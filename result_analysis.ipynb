{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../../GitHubAPI-Crawler/notebooks/2021-01-01\"\n",
    "files = os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb_1007',\n",
       " 'nb_1008',\n",
       " 'nb_1059',\n",
       " 'nb_1060',\n",
       " 'nb_1081',\n",
       " 'nb_1084',\n",
       " 'nb_1088',\n",
       " 'nb_1149',\n",
       " 'nb_1158',\n",
       " 'nb_1162',\n",
       " 'nb_1173',\n",
       " 'nb_1175',\n",
       " 'nb_1178',\n",
       " 'nb_1182',\n",
       " 'nb_1187',\n",
       " 'nb_1200',\n",
       " 'nb_1213',\n",
       " 'nb_1215',\n",
       " 'nb_1217',\n",
       " 'nb_1235',\n",
       " 'nb_1244',\n",
       " 'nb_1274',\n",
       " 'nb_1290',\n",
       " 'nb_1318',\n",
       " 'nb_1326',\n",
       " 'nb_1353',\n",
       " 'nb_1369',\n",
       " 'nb_1406',\n",
       " 'nb_1432',\n",
       " 'nb_1437',\n",
       " 'nb_1452',\n",
       " 'nb_1453',\n",
       " 'nb_1454',\n",
       " 'nb_1455',\n",
       " 'nb_1456',\n",
       " 'nb_1457',\n",
       " 'nb_1465',\n",
       " 'nb_1469',\n",
       " 'nb_1470',\n",
       " 'nb_1485',\n",
       " 'nb_1518',\n",
       " 'nb_1542',\n",
       " 'nb_1599',\n",
       " 'nb_1602',\n",
       " 'nb_1603',\n",
       " 'nb_1605',\n",
       " 'nb_1606',\n",
       " 'nb_1607',\n",
       " 'nb_1633',\n",
       " 'nb_1637',\n",
       " 'nb_1665',\n",
       " 'nb_1667',\n",
       " 'nb_1680',\n",
       " 'nb_1681',\n",
       " 'nb_1708',\n",
       " 'nb_1715',\n",
       " 'nb_1724',\n",
       " 'nb_1771',\n",
       " 'nb_636',\n",
       " 'nb_659',\n",
       " 'nb_662',\n",
       " 'nb_752',\n",
       " 'nb_769',\n",
       " 'nb_834',\n",
       " 'nb_861',\n",
       " 'nb_880',\n",
       " 'nb_881',\n",
       " 'nb_891',\n",
       " 'nb_892',\n",
       " 'nb_893',\n",
       " 'nb_913',\n",
       " 'nb_932',\n",
       " 'nb_966',\n",
       " 'nb_967',\n",
       " 'nb_973'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_files = [f for f in files if f.endswith('.py') and not f.endswith(\".ir.py\")]\n",
    "facts = [f for f in files if f.endswith('-fact')]\n",
    "diff = (set(f[:-3] for f in py_files)) - (set(f[:-5] for f in facts))\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen(f\"grep 'invo' ../../GitHubAPI-Crawler/notebooks/2021-01-01/*/CallGraph*\", shell=True, stdout=subprocess.PIPE)\n",
    "bytes = proc.stdout.read()\n",
    "arr = bytes.decode('UTF-8').split('\\n')[:-1]\n",
    "# sorted(arr, key = lambda x: int(x.split('/')[5][3:-5]))\n",
    "sorted_methods = sorted(set(x.split('\\t')[2] for x in arr))\n",
    "with open(\"call1.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join(sorted_methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for leak distribution\n",
    "proc = subprocess.Popen(f\"grep -l 'invo' ../../GitHubAPI-Crawler/notebooks/2021-01-01/*/Multi*\", shell=True, stdout=subprocess.PIPE)\n",
    "bytes = proc.stdout.read()\n",
    "arr = bytes.decode('UTF-8').split('\\n')[:-1]\n",
    "sorted(arr, key = lambda x: int(x.split('/')[5][3:-5]))\n",
    "s1 = set(x.split('/')[5][3:-5] for x in arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 126 63 100\n"
     ]
    }
   ],
   "source": [
    "proc = subprocess.Popen(f\"grep -l '' ../../GitHubAPI-Crawler/notebooks/2021-01-01/*/Final*\", shell=True, stdout=subprocess.PIPE)\n",
    "bytes = proc.stdout.read()\n",
    "arr = bytes.decode('UTF-8').split('\\n')[:-1]\n",
    "sorted(arr, key = lambda x: int(x.split('/')[5][3:-5]))\n",
    "s2 = set(x.split('/')[5][3:-5] for x in arr)\n",
    "print(len(s1), len(s2), len(s1 & s2), len(s1.symmetric_difference(s2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_23-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_33-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_50-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_56-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_64-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_134-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_163-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_167-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_187-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_259-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_286-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_288-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_295-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_347-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_447-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_528-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_535-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_539-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_620-fact/MultiUseTestLeak.csv',\n",
       " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_656-fact/MultiUseTestLeak.csv']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "sorted(sample(arr, 20), key = lambda x: int(x.split('/')[5][3:-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "class QueryManager(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.ir_path = file_path + \".ir.py\"\n",
    "        self.dir_path = file_path.replace(\".py\", \"-fact\")\n",
    "        # leaks = [\"PreProcessingLeak\"] #, \"OverlapLeak\", \"MultiUseTestLeak\"]\n",
    "        # self.leak_paths = {leak: os.path.join(self.dir_path, f'Telemetry_{leak}.csv') for leak in leaks}\n",
    "        self.leak_paths = {}\n",
    "        self.leak_paths[\"ModelPair\"] = os.path.join(self.dir_path, \"Telemetry_ModelPair.csv\")\n",
    "        self.leak_paths[\"PreProcessingLeak\"] = os.path.join(self.dir_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "        self.leak_paths[\"FinalOverlapLeak\"] = os.path.join(self.dir_path, \"FinalOverlapLeak.csv\")\n",
    "        self.leak_paths[\"FinalNoTestData\"] = os.path.join(self.dir_path, \"FinalNoTestData.csv\")\n",
    "        # self.leak_paths[\"NoValAndTestData\"] = os.path.join(self.dir_path, \"NoValAndTestData.csv\")\n",
    "        # self.leak_paths[\"NoTestData\"] = os.path.join(self.dir_path, \"NoTestData.csv\")\n",
    "    \n",
    "    def display_Leaks(self):\n",
    "        for leak in self.leak_paths.keys():\n",
    "            self.display_Leak(leak)\n",
    "    \n",
    "    def display_Leak(self, leak):\n",
    "        read_df = getattr(self, \"read_\" + leak)\n",
    "        df = read_df()\n",
    "        if len(df) > 0:\n",
    "            print(leak + \" !!!\")\n",
    "            print(df)\n",
    "\n",
    "    def read_ModelPair(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"ModelPair\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2'])\n",
    "        return df\n",
    "\n",
    "    def read_PreProcessingLeak(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"PreProcessingLeak\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2', 'des', 'src'])\n",
    "        return df\n",
    "\n",
    "    def read_OverlapLeak(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"OverlapLeak\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'testModel', 'test', 'testInvo', 'testMeth'])\n",
    "        return df\n",
    "\n",
    "    def read_FinalOverlapLeak(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"FinalOverlapLeak\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx', 'cnt'])\n",
    "        return df\n",
    "\n",
    "    def read_MultiUseTestLeak(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"MultiUseTestLeak\"], sep=\"\\t\", names=['testModel', 'test', 'testInvo', 'testMeth', 'testModel2', 'test2', 'testInvo2', 'testMeth2'])\n",
    "        return df\n",
    "\n",
    "    def read_NoValAndTestData(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"NoValAndTestData\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth'])\n",
    "        return df\n",
    "    \n",
    "    def read_NoTestData(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"NoTestData\"], sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth'])\n",
    "        return df\n",
    "    \n",
    "    def read_FinalNoTestData(self):\n",
    "        df = pd.read_csv(self.leak_paths[\"FinalNoTestData\"], sep=\"\\t\", names=['msg'])\n",
    "        return df\n",
    "\n",
    "    def query(self, file, var):\n",
    "        file_path = os.path.join(self.dir_path, file)\n",
    "        subprocess.Popen(f\"grep '{var}' {file_path}\", shell=True)\n",
    "\n",
    "    def query_pair(self, file, var1, var2=\"\"):\n",
    "        file_path = os.path.join(self.dir_path, file)\n",
    "        subprocess.Popen(f\"grep '{var1}\\t.*{var2}\\t' {file_path}\", shell=True)\n",
    "\n",
    "    def query_overlap(self, var1, var2=\"\"):\n",
    "        file_path = os.path.join(self.dir_path, \"DataOverlap.csv\")\n",
    "        subprocess.Popen(f\"grep '{var1}\\t.*{var2}\\t' {file_path}\", shell=True)\n",
    "\n",
    "    def find_flow_path(self, des, src):\n",
    "        file_path = os.path.join(self.dir_path, \"FlowFromEdge.csv\")\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", names=[\"to\", \"to_ctx\", \"from\", \"from_ctx\", \"tag\"])\n",
    "        graph = defaultdict(list)\n",
    "        df.apply(lambda x: graph[x[\"from\"]].append(x[\"to\"]), axis=1)\n",
    "        q = [[src]]\n",
    "        while True:\n",
    "            cur, *q = q\n",
    "            if cur[-1] == des:\n",
    "                print(cur)\n",
    "                break\n",
    "            if len(cur) >= 10:\n",
    "                print(\"Unfound!\")\n",
    "                break\n",
    "            for x in graph[cur[-1]]:\n",
    "                q.append(cur + [x])\n",
    "\n",
    "    \n",
    "    def find_pattern(self, pattern, lines = 10):\n",
    "        subprocess.Popen(f\"grep -C {lines} '{pattern}' {self.ir_path}\", shell=True)\n",
    "\n",
    "    def display_links(self):\n",
    "        d = {\"ori_python\": self.file_path, \n",
    "            \"ir_python\": self.ir_path}\n",
    "        for k,v in d.items():\n",
    "            display(Markdown(f\"[{k}]({v})\"))\n",
    "        dir = sorted(os.listdir(self.dir_path))\n",
    "        texts = \", \".join([f\"[{fact}]({os.path.join(self.dir_path, fact)})\" for fact in dir if fact.endswith(\"csv\")])\n",
    "        display(Markdown(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = \"../tests/inputs/\"\n",
    "# file_path = os.path.join(dir_path, \"nb_175471.py\")\n",
    "# q = QueryManager(file_path)\n",
    "# q.display_links()\n",
    "# q.display_Leaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>future-sales-prediction-playground.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>simple-lgbmregressor-baseline.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>predict-sales-time-series-with-cnn.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>future-sales-xgboost-top-3.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>predict-future-sales-top-11-solution.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ensemble-learning-part-2-blend-a-smoothie.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sales-forecast-lstm-67-beginner-friendly.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>learn-machine-learning-faster-1.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              nb  model   pre  overlap  multi\n",
       "3          future-sales-prediction-playground.py   True  True    False  False\n",
       "20              simple-lgbmregressor-baseline.py   True  True    False  False\n",
       "22         predict-sales-time-series-with-cnn.py   True  True    False  False\n",
       "35                 future-sales-xgboost-top-3.py   True  True    False  False\n",
       "37       predict-future-sales-top-11-solution.py   True  True    False  False\n",
       "42  ensemble-learning-part-2-blend-a-smoothie.py   True  True     True  False\n",
       "43   sales-forecast-lstm-67-beginner-friendly.py   True  True    False   True\n",
       "44            learn-machine-learning-faster-1.py   True  True    False  False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"pre\"] == True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[ori_python](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution.py)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[ir_python](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution.py.ir.py)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Alias.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Alias.csv), [CallGraphEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/CallGraphEdge.csv), [DataOverlap.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/DataOverlap.csv), [FieldPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FieldPointsTo.csv), [FilteredTests.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FilteredTests.csv), [FinalNoTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FinalNoTestData.csv), [FinalNoTestDataWithMultiUse.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FinalNoTestDataWithMultiUse.csv), [FinalOverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FinalOverlapLeak.csv), [FlowFrom.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FlowFrom.csv), [FlowFromEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FlowFromEdge.csv), [FlowFromExtended.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/FlowFromExtended.csv), [IndexContentPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/IndexContentPointsTo.csv), [InvokeEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/InvokeEdge.csv), [InvokePath.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/InvokePath.csv), [ModelPair.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/ModelPair.csv), [ModelPairCandidate.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/ModelPairCandidate.csv), [MultiUseTestLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/MultiUseTestLeak.csv), [NoTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/NoTestData.csv), [NoValAndTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/NoValAndTestData.csv), [OverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/OverlapLeak.csv), [PreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/PreProcessingLeak.csv), [ScoredDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/ScoredDataWithModel.csv), [TaintStartsTarget.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/TaintStartsTarget.csv), [Telemetry_FinalPreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Telemetry_FinalPreProcessingLeak.csv), [Telemetry_ModelPair.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Telemetry_ModelPair.csv), [Telemetry_MultiUseTestLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Telemetry_MultiUseTestLeak.csv), [Telemetry_OverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Telemetry_OverlapLeak.csv), [Telemetry_PreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/Telemetry_PreProcessingLeak.csv), [TestDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/TestDataWithModel.csv), [TorchModelWithData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/TorchModelWithData.csv), [TrainingDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/TrainingDataWithModel.csv), [ValDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/ValDataWithModel.csv), [ValOrTestDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/ValOrTestDataWithModel.csv), [VarEquals.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/VarEquals.csv), [VarPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/predict-future-sales-top-11-solution-fact/VarPointsTo.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPair !!!\n",
      "  trainModel     train trainInvo         trainMeth  ctx1 testModel     test  testInvo          testMeth  ctx2\n",
      "0    model_0    trainx   $invo51  XGBRegressor.fit  [, ]   model_0  _var117   $invo52  XGBModel.predict  [, ]\n",
      "1    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]\n",
      "2    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]\n",
      "PreProcessingLeak !!!\n",
      "   trainModel     train trainInvo         trainMeth  ctx1 testModel     test  testInvo          testMeth  ctx2        des                src\n",
      "0     model_0    trainx   $invo51  XGBRegressor.fit  [, ]   model_0  _var117   $invo52  XGBModel.predict  [, ]      tfidf            _var467\n",
      "1     model_0    trainx   $invo51  XGBRegressor.fit  [, ]   model_0  _var117   $invo52  XGBModel.predict  [, ]    _var468            _var467\n",
      "2     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]   groups_2   train_test_set_6\n",
      "3     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]   groups_5  train_test_set_11\n",
      "4     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]   groups_8  train_test_set_16\n",
      "5     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]  groups_11  train_test_set_30\n",
      "6     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]      tfidf            _var467\n",
      "7     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2     valx  $invo206  XGBModel.predict  [, ]    _var468            _var467\n",
      "8     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]   groups_2   train_test_set_6\n",
      "9     model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]   groups_5  train_test_set_11\n",
      "10    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]   groups_8  train_test_set_16\n",
      "11    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]  groups_11  train_test_set_30\n",
      "12    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]      tfidf            _var467\n",
      "13    model_2  trainx_0  $invo205  XGBRegressor.fit  [, ]   model_2    testx  $invo211  XGBModel.predict  [, ]    _var468            _var467\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../../GitHubAPI-Crawler/kaggle-notebooks/competitive-data-science-predict-future-sales/\"\n",
    "file_path = os.path.join(dir_path, \"predict-future-sales-top-11-solution.py\")\n",
    "q = QueryManager(file_path)\n",
    "q.display_links()\n",
    "q.display_Leaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2926260/1907250001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_flow_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inde_variables_0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "q.find_flow_path('x_train', 'inde_variables_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\t[, ]\t_var106\t[, ]\tnormal\n",
      "X_test\t[, ]\t_var107\t[, ]\tnormal\n",
      "X_test\t[, ]\tcur_Xy\t[, ]\tdata\n",
      "X_test\t[, ]\tcur_Xy\t[, ]\tnormal\n",
      "X_test\t[, ]\t_var141\t[, ]\tnormal\n",
      "X_test\t[, ]\t_var143\t[, ]\tnormal\n",
      "X_test\t[, ]\tcur_len\t[, ]\tnormal\n",
      "X_test\t[, ]\tcur_Xy_test\t[, ]\tdata\n",
      "X_test\t[, ]\tcur_Xy_test\t[, ]\tnormal\n",
      "X_test\t[, ]\tX_test\t[, ]\tdata\n",
      "X_test\t[, ]\tX_test\t[, ]\tnormal\n",
      "X_test\t[, ]\tX_test\t[, ]\tequiv\n",
      "X_test\t[, ]\tprocessed_trainset\t[, ]\tdata\n",
      "X_test\t[, ]\tprocessed_trainset\t[, ]\tnormal\n",
      "X_test\t[, ]\t_var142\t[, ]\tnormal\n",
      "X_test\t[, ]\ttrain_test_perc\t[, ]\tnormal\n",
      "_var151\t[, ]\tX_test\t[, ]\tnormal\n",
      "predictions\t[, ]\tX_test\t[, ]\tnormal\n",
      "_var152\t[, ]\tX_test\t[, ]\tnormal\n",
      "X_test_1\t[, ]\tX_test\t[, ]\tdata\n",
      "X_test_1\t[, ]\tX_test\t[, ]\tnormal\n",
      "X_test_1\t[, ]\tX_test\t[, ]\tequiv\n",
      "predictions_1\t[, ]\tX_test\t[, ]\tnormal\n",
      "predictions_4\t[, ]\tX_test\t[, ]\tnormal\n"
     ]
    }
   ],
   "source": [
    "q.query_pair(\"FlowFrom.csv\", 'X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\t[, ]\t_var136\t[, ]\n",
      "X_test\t[, ]\tcur_Xy\t[, ]\n",
      "X_test\t[, ]\tcur_Xy_test\t[, ]\n",
      "X_test\t[, ]\tX_test\t[, ]\n",
      "X_test\t[, ]\t_var151\t[, ]\n",
      "X_test\t[, ]\ty_test\t[, ]\n",
      "X_test\t[, ]\t_var159\t[, ]\n",
      "X_test\t[, ]\tprocessed_trainset\t[, ]\n",
      "X_test\t[, ]\tcur_Xy_1\t[, ]\n",
      "X_test\t[, ]\tX_test_1\t[, ]\n",
      "X_test\t[, ]\tcur_Xy_test_1\t[, ]\n",
      "X_test\t[, ]\ty_test_1\t[, ]\n",
      "X_test\t[, ]\t_var114\t[, ]\n",
      "X_test\t[, ]\t_var116\t[, ]\n",
      "X_test\t[, ]\t_var120\t[, ]\n",
      "X_test\t[, ]\t_var132\t[, ]\n"
     ]
    }
   ],
   "source": [
    "# q.find_pattern('model.fit', 20)\n",
    "q.query_overlap('X_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Kaggle Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            nb       msg    t1    t2    t3     t  model    pre  overlap  multi  length\n",
       " 0      nb_0.py  Success!  0.05  3.36  1.37  4.78   True   True    False  False    1021\n",
       " 1      nb_1.py  Success!  0.01  1.49  0.31  1.81  False  False    False  False     342\n",
       " 2      nb_2.py  Success!  0.02  1.20  0.42  1.63  False  False    False  False     700\n",
       " 3      nb_3.py  Success!  0.06  2.76  1.91  4.73  False  False    False  False     480\n",
       " 4      nb_4.py  Success!  0.10  4.97  2.16  7.23   True  False    False  False    1735\n",
       " ..         ...       ...   ...   ...   ...   ...    ...    ...      ...    ...     ...\n",
       " 165  nb_156.py  Success!  0.04  2.97  1.12  4.14   True   True     True  False     738\n",
       " 166  nb_157.py  Success!  0.01  1.15  0.33  1.49   True   True    False  False     207\n",
       " 167  nb_158.py  Success!  0.00  0.59  0.23  0.81  False  False    False  False     486\n",
       " 168  nb_159.py  Success!  0.01  1.67  0.48  2.16  False  False    False   True     590\n",
       " 169  nb_160.py  Success!  0.02  1.46  0.82  2.30  False  False    False  False     313\n",
       " \n",
       " [157 rows x 11 columns],\n",
       "             nb       msg    t1    t2    t3      t  model   pre  overlap  multi  length\n",
       " 0      nb_0.py  Success!  0.05  3.36  1.37   4.78   True  True    False  False    1021\n",
       " 5      nb_5.py  Success!  0.07  3.32  1.73   5.12   True  True    False   True    1256\n",
       " 10     nb_8.py  Success!  0.22  4.78  7.67  12.67   True  True    False  False    3153\n",
       " 11     nb_9.py  Success!  0.08  3.18  1.70   4.96   True  True    False   True     844\n",
       " 13    nb_11.py  Success!  0.05  2.87  0.83   3.75   True  True    False  False     392\n",
       " ..         ...       ...   ...   ...   ...    ...    ...   ...      ...    ...     ...\n",
       " 162  nb_153.py  Success!  0.07  2.24  2.41   4.72   True  True    False   True     753\n",
       " 163  nb_154.py  Success!  0.07  2.86  1.74   4.67   True  True    False  False     944\n",
       " 164  nb_155.py  Success!  0.04  2.70  1.14   3.89   True  True    False  False     650\n",
       " 165  nb_156.py  Success!  0.04  2.97  1.12   4.14   True  True     True  False     738\n",
       " 166  nb_157.py  Success!  0.01  1.15  0.33   1.49   True  True    False  False     207\n",
       " \n",
       " [88 rows x 11 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dir_path = \"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/kaggle-notebooks/titanic_voted\"\n",
    "[\"house-prices-advanced-regression-techniques_recent\", \"titanic_recent\"]\n",
    "df = pd.read_csv(os.path.join(dir_path, \"log.txt\"), sep=\"\\t\", index_col=False, names=[\"nb\", \"msg\", \"t1\", \"t2\", \"t3\", \"t\"])\n",
    "df = df[df[\"msg\"] == \"Success!\"]\n",
    "df[\"nb\"] = df[\"nb\"].map(lambda x: os.path.join(dir_path, x))\n",
    "\n",
    "# df = df[df[\"nb\"].map(lambda x: os.path.exists(x.replace(\".py\", \"-fact\")))]\n",
    "def find_results(file_path):\n",
    "    file_length = len(open(file_path).read().splitlines())\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    model_pairs = os.path.join(file_path, \"ModelPair.csv\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    overlap_leaks = os.path.join(file_path, \"FinalOverlapLeak.csv\")\n",
    "    multi_leaks = os.path.join(file_path, \"FinalNoTestDataWithMultiUse.csv\")\n",
    "    has_pairs = len(open(model_pairs).read().splitlines()) > 0\n",
    "    has_pre_leaks = len(open(pre_leaks).read().splitlines()) > 0\n",
    "    has_overlap_leaks = len(open(overlap_leaks).read().splitlines()) > 0\n",
    "    has_multi_leaks = len(open(multi_leaks).read().splitlines()) > 0\n",
    "    return {\"model\": has_pairs, \"pre\": has_pre_leaks, \"overlap\": has_overlap_leaks, \"multi\": has_multi_leaks, \"length\":file_length}\n",
    "# df.merge(df[\"nb\"].map(find_results), left_index=True, right_index=True)\n",
    "applied_df = df.apply(lambda row: find_results(row[\"nb\"]), axis='columns', result_type='expand')\n",
    "df = pd.concat([df, applied_df], axis='columns')\n",
    "df[\"nb\"] = df[\"nb\"].map(lambda x: '/'.join(x.split('/')[-1:]))\n",
    "df, df[df[\"pre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[ori_python](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11.py)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[ir_python](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11.py.ir.py)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Alias.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Alias.csv), [CallGraphEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/CallGraphEdge.csv), [DataOverlap.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/DataOverlap.csv), [FieldPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FieldPointsTo.csv), [FilteredTests.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FilteredTests.csv), [FinalNoTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FinalNoTestData.csv), [FinalNoTestDataWithMultiUse.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FinalNoTestDataWithMultiUse.csv), [FinalOverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FinalOverlapLeak.csv), [FlowFrom.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FlowFrom.csv), [FlowFromEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FlowFromEdge.csv), [FlowFromExtended.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/FlowFromExtended.csv), [IndexContentPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/IndexContentPointsTo.csv), [InvokeEdge.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/InvokeEdge.csv), [InvokePath.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/InvokePath.csv), [ModelPair.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/ModelPair.csv), [ModelPairCandidate.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/ModelPairCandidate.csv), [MultiUseTestLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/MultiUseTestLeak.csv), [NoTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/NoTestData.csv), [NoValAndTestData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/NoValAndTestData.csv), [OverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/OverlapLeak.csv), [PreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/PreProcessingLeak.csv), [ScoredDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/ScoredDataWithModel.csv), [TaintStartsTarget.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/TaintStartsTarget.csv), [Telemetry_FinalPreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Telemetry_FinalPreProcessingLeak.csv), [Telemetry_ModelPair.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Telemetry_ModelPair.csv), [Telemetry_MultiUseTestLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Telemetry_MultiUseTestLeak.csv), [Telemetry_OverlapLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Telemetry_OverlapLeak.csv), [Telemetry_PreProcessingLeak.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/Telemetry_PreProcessingLeak.csv), [TestDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/TestDataWithModel.csv), [TorchModelWithData.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/TorchModelWithData.csv), [TrainingDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/TrainingDataWithModel.csv), [ValDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/ValDataWithModel.csv), [ValOrTestDataWithModel.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/ValOrTestDataWithModel.csv), [VarEquals.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/VarEquals.csv), [VarPointsTo.csv](../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/nb_11-fact/VarPointsTo.csv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPair !!!\n",
      "        trainModel    train trainInvo                   trainMeth  ctx1        testModel     test  testInvo                                           testMeth  ctx2\n",
      "0         logreg_0  X_train  $invo113      LogisticRegression.fit  [, ]         logreg_0  X_train  $invo115                           LogisticRegression.score  [, ]\n",
      "1         logreg_0  X_train  $invo113      LogisticRegression.fit  [, ]         logreg_0   X_test  $invo114                         LogisticRegression.predict  [, ]\n",
      "2  random_forest_0  X_train  $invo117  RandomForestClassifier.fit  [, ]  random_forest_0  X_train  $invo119  RandomForestRegressor | ExtraTreesRegressor | ...  [, ]\n",
      "3  random_forest_0  X_train  $invo117  RandomForestClassifier.fit  [, ]  random_forest_0   X_test  $invo118  RandomForestRegressor | ExtraTreesRegressor | ...  [, ]\n",
      "PreProcessingLeak !!!\n",
      "        trainModel    train trainInvo                   trainMeth  ctx1        testModel    test  testInvo                                           testMeth  ctx2               des      src\n",
      "0         logreg_0  X_train  $invo113      LogisticRegression.fit  [, ]         logreg_0  X_test  $invo114                         LogisticRegression.predict  [, ]            _var67   _var66\n",
      "1         logreg_0  X_train  $invo113      LogisticRegression.fit  [, ]         logreg_0  X_test  $invo114                         LogisticRegression.predict  [, ]  average_age_test  _var134\n",
      "2         logreg_0  X_train  $invo113      LogisticRegression.fit  [, ]         logreg_0  X_test  $invo114                         LogisticRegression.predict  [, ]      std_age_test  _var136\n",
      "3  random_forest_0  X_train  $invo117  RandomForestClassifier.fit  [, ]  random_forest_0  X_test  $invo118  RandomForestRegressor | ExtraTreesRegressor | ...  [, ]            _var67   _var66\n",
      "4  random_forest_0  X_train  $invo117  RandomForestClassifier.fit  [, ]  random_forest_0  X_test  $invo118  RandomForestRegressor | ExtraTreesRegressor | ...  [, ]  average_age_test  _var134\n",
      "5  random_forest_0  X_train  $invo117  RandomForestClassifier.fit  [, ]  random_forest_0  X_test  $invo118  RandomForestRegressor | ExtraTreesRegressor | ...  [, ]      std_age_test  _var136\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../../GitHubAPI-Crawler/kaggle-notebooks/titanic_voted/\"\n",
    "file_path = os.path.join(dir_path, \"nb_11.py\")\n",
    "q = QueryManager(file_path)\n",
    "q.display_links()\n",
    "q.display_Leaks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results(file_path):\n",
    "    file_length = len(open(file_path).read().splitlines())\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    model_pairs = os.path.join(file_path, \"ModelPair.csv\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    overlap_leaks = os.path.join(file_path, \"FinalOverlapLeak.csv\")\n",
    "    multi_leaks = os.path.join(file_path, \"FinalNoTestDataWithMultiUse.csv\")\n",
    "    try:\n",
    "        has_pairs = len(open(model_pairs).read().splitlines()) > 0\n",
    "        has_pre_leaks = len(open(pre_leaks).read().splitlines()) > 0\n",
    "        has_overlap_leaks = len(open(overlap_leaks).read().splitlines()) > 0\n",
    "        has_multi_leaks = len(open(multi_leaks).read().splitlines()) > 0\n",
    "        return {\"model\": has_pairs, \"pre\": has_pre_leaks, \"overlap\": has_overlap_leaks, \"multi\": has_multi_leaks, \"length\":file_length}\n",
    "    except:\n",
    "        return {\"model\": False, \"pre\": False, \"overlap\": False, \"multi\": False, \"length\":file_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     nb  model    pre  \\\n",
       "0     ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "1     ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "2     ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   True  False   \n",
       "3     ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "4     ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "...                                                 ...    ...    ...   \n",
       "1152  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "1153  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "1154  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "1155  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "1156  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  False  False   \n",
       "\n",
       "      overlap  multi  length  \n",
       "0       False  False     225  \n",
       "1       False  False     218  \n",
       "2       False   True     379  \n",
       "3       False  False    1153  \n",
       "4       False  False    1339  \n",
       "...       ...    ...     ...  \n",
       "1152    False  False     961  \n",
       "1153    False  False     902  \n",
       "1154    False  False     791  \n",
       "1155    False  False     849  \n",
       "1156    False  False    1016  \n",
       "\n",
       "[1157 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze sample log\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "file_path = \"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/tutorial.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", index_col=False, names=[\"nb\"])\n",
    "df = df[[\"nb\"]]\n",
    "df[\"nb\"] = df[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", x))\n",
    "# df.merge(df[\"nb\"].map(find_results), left_index=True, right_index=True)\n",
    "applied_df = df.apply(lambda row: find_results(row[\"nb\"]), axis='columns', result_type='expand')\n",
    "df = pd.concat([df, applied_df], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584.1849611063094"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01/nb_197.py</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-01/nb_556.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-09-01/nb_1279.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-09-01/nb_1280.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-09-01/nb_2596.py</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2021-09-30/nb_2531.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2021-09-30/nb_2799.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2021-09-30/nb_3004.py</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>2021-09-30/nb_3812.py</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2021-09-30/nb_3819.py</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         nb  model    pre  overlap  multi\n",
       "2      2021-09-01/nb_197.py   True  False    False   True\n",
       "5      2021-09-01/nb_556.py   True   True    False   True\n",
       "14    2021-09-01/nb_1279.py   True   True    False  False\n",
       "15    2021-09-01/nb_1280.py   True   True     True  False\n",
       "23    2021-09-01/nb_2596.py   True  False    False   True\n",
       "...                     ...    ...    ...      ...    ...\n",
       "1123  2021-09-30/nb_2531.py   True   True    False  False\n",
       "1124  2021-09-30/nb_2799.py   True   True    False  False\n",
       "1125  2021-09-30/nb_3004.py   True   True    False  False\n",
       "1143  2021-09-30/nb_3812.py   True  False     True   True\n",
       "1150  2021-09-30/nb_3819.py   True  False    False   True\n",
       "\n",
       "[171 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"nb\"] = df[\"nb\"].map(lambda x: '/'.join(x.split('/')[-2:]))\n",
    "df[df[\"pre\"] | df[\"overlap\"] | df[\"multi\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Leakage Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01/nb_0.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.82</td>\n",
       "      <td>3.53</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01/nb_1.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01/nb_2.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-01/nb_3.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-01/nb_4.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>2021-09-30/nb_4130.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.23</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>2021-09-30/nb_4131.py</td>\n",
       "      <td>Failed to parse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>2021-09-30/nb_4132.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>2021-09-30/nb_4133.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>2021-09-30/nb_4134.py</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107603 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         nb              msg    t1    t2    t3     t\n",
       "0        2021-09-01/nb_0.py         Success!  0.10  2.82  3.53  6.44\n",
       "1        2021-09-01/nb_1.py         Success!  0.02  1.86  0.60  2.48\n",
       "2        2021-09-01/nb_2.py         Success!  0.04  2.03  0.69  2.76\n",
       "3        2021-09-01/nb_3.py         Success!  0.02  2.08  0.46  2.56\n",
       "4        2021-09-01/nb_4.py         Success!  0.02  1.77  0.40  2.19\n",
       "...                     ...              ...   ...   ...   ...   ...\n",
       "4456  2021-09-30/nb_4130.py         Success!  0.08  3.56  2.23  5.87\n",
       "4458  2021-09-30/nb_4131.py  Failed to parse   NaN   NaN   NaN   NaN\n",
       "4459  2021-09-30/nb_4132.py         Success!  0.01  2.44  0.49  2.94\n",
       "4460  2021-09-30/nb_4133.py         Success!  0.03  2.73  0.88  3.64\n",
       "4461  2021-09-30/nb_4134.py         Success!  0.02  3.14  0.48  3.64\n",
       "\n",
       "[107603 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze whole log\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "dates = [\"2021-09-\" + str(date).zfill(2) for date in range(1, 31)]\n",
    "df = pd.DataFrame()\n",
    "for date in dates:\n",
    "    file_path = f\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/notebooks/{date}/log.txt\"\n",
    "    df_temp = pd.read_csv(file_path, sep=\"\\t\", index_col=False, names=[\"nb\", \"msg\", \"t1\", \"t2\", \"t3\", \"t\"])\n",
    "    df_temp[\"nb\"] = df_temp[\"nb\"].map(lambda x: os.path.join(date, x))\n",
    "    df = pd.concat([df, df_temp])\n",
    "df = df[df[\"msg\"] != \"Conversion failed\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nb\"] = df[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", \"GitHub-data\", \"notebooks\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    model_pairs = os.path.join(file_path, \"ModelPair.csv\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    overlap_leaks = os.path.join(file_path, \"FinalOverlapLeak.csv\")\n",
    "    multi_leaks = os.path.join(file_path, \"FinalNoTestDataWithMultiUse.csv\")\n",
    "    try:\n",
    "        has_pairs = len(open(model_pairs).read().splitlines()) > 0\n",
    "        has_pre_leaks = len(open(pre_leaks).read().splitlines()) > 0\n",
    "        has_overlap_leaks = len(open(overlap_leaks).read().splitlines()) > 0\n",
    "        has_multi_leaks = len(open(multi_leaks).read().splitlines()) > 0\n",
    "        return {\"model\": has_pairs, \"pre\": has_pre_leaks, \"overlap\": has_overlap_leaks, \"multi\": has_multi_leaks}\n",
    "    except:\n",
    "        print(file_path)\n",
    "        return {\"model\": False, \"pre\": False, \"overlap\": False, \"multi\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"nb\", \"msg\"]]\n",
    "df = df[df[\"msg\"] == \"Success!\"]\n",
    "applied_df = df.apply(lambda row: find_results(row[\"nb\"]), axis='columns', result_type='expand')\n",
    "df = pd.concat([df, applied_df], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all-leaks.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[df[\"pre\"] | df[\"overlap\"] | df[\"multi\"]].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"nb\"] = sample[\"nb\"].map(lambda x: \"/\".join(x.split(\"/\")[1:]))\n",
    "with open(\"sample-leaks.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(sample[\"nb\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7623, 32, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"msg\"] == \"Failed to parse\"]), len(df[df[\"msg\"] == \"Failed to generate facts\"]), len(df[df[\"msg\"] == \"Failed to parse transformed file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"msg\"] == \"Failed to analyze\"]) + len(df[df[\"msg\"] == \"Failed to infer types\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2021-09-04/nb_1688.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>2021-09-06/nb_2524.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>2021-09-06/nb_2526.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>2021-09-07/nb_1517.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-09-10/nb_6.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-09-10/nb_7.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-09-10/nb_8.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>2021-09-13/nb_746.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2021-09-13/nb_747.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>2021-09-17/nb_1575.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>2021-09-20/nb_2545.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>2021-09-21/nb_1576.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2021-09-23/nb_2151.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>2021-09-23/nb_2419.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2021-09-23/nb_2420.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2021-09-27/nb_702.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>2021-09-27/nb_2825.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2021-09-30/nb_1531.py</td>\n",
       "      <td>Failed to parse transformed file</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         nb                               msg  t1  t2  t3   t\n",
       "1858  2021-09-04/nb_1688.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2783  2021-09-06/nb_2524.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2785  2021-09-06/nb_2526.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "1714  2021-09-07/nb_1517.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "7        2021-09-10/nb_6.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "8        2021-09-10/nb_7.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "9        2021-09-10/nb_8.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "816    2021-09-13/nb_746.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "818    2021-09-13/nb_747.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "1709  2021-09-17/nb_1575.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2831  2021-09-20/nb_2545.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "1738  2021-09-21/nb_1576.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2311  2021-09-23/nb_2151.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2593  2021-09-23/nb_2419.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "2594  2021-09-23/nb_2420.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "755    2021-09-27/nb_702.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "3071  2021-09-27/nb_2825.py  Failed to parse transformed file NaN NaN NaN NaN\n",
       "1640  2021-09-30/nb_1531.py  Failed to parse transformed file NaN NaN NaN NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"msg\"] == \"Failed to parse transformed file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Sample Leakage Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nb       msg  model  \\\n",
       "1    ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "2    ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "3    ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "4    ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "6    ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "..                                                 ...       ...    ...   \n",
       "99   ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "100  ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "101  ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "102  ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "104  ../../GitHubAPI-Crawler/../GitHubAPI-Crawler/G...  Success!   True   \n",
       "\n",
       "       pre  overlap  multi  \n",
       "1     True    False   True  \n",
       "2     True    False  False  \n",
       "3    False    False   True  \n",
       "4     True    False   True  \n",
       "6    False    False   True  \n",
       "..     ...      ...    ...  \n",
       "99   False     True  False  \n",
       "100  False     True   True  \n",
       "101  False     True  False  \n",
       "102  False    False   True  \n",
       "104   True    False  False  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze sample log\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "file_path = \"sample-leaks.txt-log.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", index_col=False, names=[\"nb\", \"msg\", \"t1\", \"t2\", \"t3\", \"t\"])\n",
    "df = df[[\"nb\", \"msg\"]]\n",
    "df[\"nb\"] = df[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", x))\n",
    "df = df[df[\"msg\"] == \"Success!\"]\n",
    "applied_df = df.apply(lambda row: find_results(row[\"nb\"]), axis='columns', result_type='expand')\n",
    "df = pd.concat([df, applied_df], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    minpath = os.path.join(file_path, \"MinPathLength.csv\")\n",
    "    pre = pd.read_csv(pre_leaks, sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2', 'des', 'src'])\n",
    "    df = pd.read_csv(minpath, sep=\"\\t\", names=['to', 'toCtx', 'from', 'fromCtx', 'ctx1', 'path', 'length'])\n",
    "    df2 = pre.merge(df, left_on=[\"train\",\"ctx1\", \"des\"], right_on=[\"to\", \"toCtx\", \"from\"])\n",
    "    if len(df2) == 0:\n",
    "        print(pre.merge(df, left_on=[\"train\"], right_on=[\"to\"]))\n",
    "    return df2[\"length\"]\n",
    "\n",
    "def find_length2(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_OverlapLeak.csv\")\n",
    "    minpath = os.path.join(file_path, \"MinPathLength.csv\")\n",
    "    over = pd.read_csv(pre_leaks, sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2'])\n",
    "    df = pd.read_csv(minpath, sep=\"\\t\", names=['to', 'toCtx', 'from', 'fromCtx', 'ctx1', 'path', 'length'])\n",
    "    # df = over.merge(df, left_on=[\"train\",\"ctx1\", \"test\", \"ctx2\"], right_on=[\"to\", \"toCtx\", \"from\", 'fromCtx'])\n",
    "    df = over.merge(df, left_on=[\"test\", \"ctx2\", \"train\",\"ctx1\"], right_on=[\"to\", \"toCtx\", \"from\", 'fromCtx'])\n",
    "    return df[\"length\"]\n",
    "\n",
    "# def find_crosses(file_path):\n",
    "#     file_path = file_path.replace(\".py\", \"-fact\")\n",
    "#     pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "#     minpath = os.path.join(file_path, \"PathCrossContext.csv\")\n",
    "#     pre = pd.read_csv(pre_leaks, sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2', 'des', 'src'])\n",
    "#     df = pd.read_csv(minpath, sep=\"\\t\", names=['to', 'toCtx', 'from', 'fromCtx', 'ctx1', 'path', 'length'])\n",
    "#     df = pre.merge(df, left_on=[\"train\",\"ctx1\", \"src\"], right_on=[\"to\", \"toCtx\", \"from\"])\n",
    "#     return df[\"length\"]\n",
    "\n",
    "r = df[df[\"pre\"]==True][\"nb\"].map(find_length)\n",
    "# find_length(df[\"nb\"].loc[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      7\n",
       "2      9\n",
       "2      9\n",
       "2      9\n",
       "2      9\n",
       "      ..\n",
       "96     3\n",
       "96     2\n",
       "96     2\n",
       "104    1\n",
       "104    1\n",
       "Name: nb, Length: 264, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.percentile(r.explode(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing All Leakage Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99833</th>\n",
       "      <td>4455</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99834</th>\n",
       "      <td>4456</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99835</th>\n",
       "      <td>4459</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99836</th>\n",
       "      <td>4460</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99837</th>\n",
       "      <td>4461</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99838 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb  \\\n",
       "0               0  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "1               1  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "2               2  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "3               3  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "4               4  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "...           ...                                                ...   \n",
       "99833        4455  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99834        4456  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99835        4459  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99836        4460  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99837        4461  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "\n",
       "            msg  train  val  test  model  pre  overlap  multi  \n",
       "0      Success!      3    3     2      3  198        0   True  \n",
       "1      Success!      0    0     0      0    0        0  False  \n",
       "2      Success!      5    5     0      5    5        0   True  \n",
       "3      Success!      7    1     6      7    0        0  False  \n",
       "4      Success!      1    0     3      1    0        0  False  \n",
       "...         ...    ...  ...   ...    ...  ...      ...    ...  \n",
       "99833  Success!      0    0     0      0    0        0  False  \n",
       "99834  Success!     12   18     0     12  128        0   True  \n",
       "99835  Success!      1    0     2      1    0        0  False  \n",
       "99836  Success!      2    0     1      1    0        0  False  \n",
       "99837  Success!      1    0     1      1    0        0  False  \n",
       "\n",
       "[99838 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data = pd.read_csv(\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/leak_info.txt\")\n",
    "data[\"nb\"] = data[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>45</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99726</th>\n",
       "      <td>4342</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99810</th>\n",
       "      <td>4428</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99817</th>\n",
       "      <td>4438</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99818</th>\n",
       "      <td>4439</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99820</th>\n",
       "      <td>4441</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10056 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb       msg  train  val  test  model  pre  overlap  multi\n",
       "17             18  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      1    0     0      0    0        0  False\n",
       "38             40  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      3    6     0      0    0        0  False\n",
       "39             41  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      3    6     0      0    0        0  False\n",
       "40             42  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      2    4     0      0    0        0  False\n",
       "41             45  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      3    6     0      0    0        0  False\n",
       "...           ...                                                ...       ...    ...  ...   ...    ...  ...      ...    ...\n",
       "99726        4342  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      5    0     0      0    0        0  False\n",
       "99810        4428  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      1    0     0      0    0        0  False\n",
       "99817        4438  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      1    1     0      0    0        0  False\n",
       "99818        4439  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      4    4     0      0    0        0  False\n",
       "99820        4441  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!      4    4     0      0    0        0  False\n",
       "\n",
       "[10056 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data[\"train\"] == 0) & ((data[\"test\"] >=1) | (data[\"val\"] >=1))]) /len(data)\n",
    "len(data[data[\"multi\"]]) /len(data)\n",
    "# sum(data[\"overlap\"]) / sum(data[\"model\"])\n",
    "data[(data['model'] == 0) & (data['train'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leakage Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>105</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>106</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99758</th>\n",
       "      <td>4376</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99779</th>\n",
       "      <td>4397</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99800</th>\n",
       "      <td>4418</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99824</th>\n",
       "      <td>4446</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99834</th>\n",
       "      <td>4456</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12323 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb  \\\n",
       "0               0  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "2               2  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "6               6  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "88            105  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "89            106  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "...           ...                                                ...   \n",
       "99758        4376  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99779        4397  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99800        4418  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99824        4446  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99834        4456  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "\n",
       "            msg  train  val  test  model  pre  overlap  multi  \n",
       "0      Success!      3    3     2      3  198        0   True  \n",
       "2      Success!      5    5     0      5    5        0   True  \n",
       "6      Success!      1    0     2      1   12        0  False  \n",
       "88     Success!      1    0     1      1    2        0  False  \n",
       "89     Success!      1    0     1      1    2        0  False  \n",
       "...         ...    ...  ...   ...    ...  ...      ...    ...  \n",
       "99758  Success!      4    5     0      5   10        0   True  \n",
       "99779  Success!      4    5     0      5   10        0   True  \n",
       "99800  Success!      5    5     0      5   10        0   True  \n",
       "99824  Success!      4   16     0      4   24        0   True  \n",
       "99834  Success!     12   18     0     12  128        0   True  \n",
       "\n",
       "[12323 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = data[data[\"pre\"] > 0]\n",
    "pre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3605/4105225879.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['leak_lengths'] = pre['nb'].map(find_results)\n"
     ]
    }
   ],
   "source": [
    "def find_results(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    taints = os.path.join(file_path, \"TaintStartsTarget.csv\")\n",
    "    involoc = os.path.join(file_path, \"InvokeLineno.facts\")\n",
    "    lineno = os.path.join(file_path, \"LinenoMapping.facts\")\n",
    "\n",
    "    pre = pd.read_csv(pre_leaks, sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'testInvo', 'testMeth', 'ctx2', 'des', 'src'])\n",
    "    leaksrc = pd.read_csv(taints, sep=\"\\t\", names=['to', 'toCtx', 'from', 'fromCtx', 'invo', 'meth', 'label'])\n",
    "    merged =  pd.merge(pre, leaksrc, left_on=\"src\", right_on=\"from\")\n",
    "    \n",
    "    involoc = pd.read_csv(involoc, sep=\"\\t\", names=['invo', 'line']).set_index('invo').squeeze().to_dict()\n",
    "    lineno_map = pd.read_csv(lineno, sep=\"\\t\", names=['line', 'line_o']).set_index('line').squeeze().to_dict()\n",
    "    def get_diff(row):\n",
    "        try:\n",
    "            return abs(lineno_map[involoc[row['invo']]] - lineno_map[involoc[row['trainInvo']]])\n",
    "        except KeyError:\n",
    "            return -1\n",
    "    diff = merged[['trainInvo', 'invo']].apply(get_diff, axis=1)\n",
    "    return diff[diff >= 0].to_list()\n",
    "\n",
    "pre['leak_lengths'] = pre['nb'].map(find_results)\n",
    "# pre['file_length'] = pre['nb'].map(lambda x: len(open(x).read().splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3605/2061926809.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['file_length'] = pre['nb'].map(lambda x: len(open(x).read().splitlines()))\n",
      "/tmp/ipykernel_3605/2061926809.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre[\"frac\"] = pre.apply(lambda l: [x/l[\"file_length\"] for x in l[\"leak_lengths\"]], axis=1)\n"
     ]
    }
   ],
   "source": [
    "pre['file_length'] = pre['nb'].map(lambda x: len(open(x).read().splitlines()))\n",
    "pre[\"frac\"] = pre.apply(lambda l: [x/l[\"file_length\"] for x in l[\"leak_lengths\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003563    52200\n",
       "0.405498    28803\n",
       "0.440705    28800\n",
       "0.403780    28800\n",
       "0.439103    28800\n",
       "            ...  \n",
       "0.432584        1\n",
       "0.064045        1\n",
       "0.060674        1\n",
       "0.058427        1\n",
       "0.642226        1\n",
       "Name: frac, Length: 65099, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = pd.cut(pre[\"frac\"].explode(), [x*0.1 for x in range(0, 10, 2)]).value_counts().sort_index() \n",
    "mean = pre[\"frac\"].explode()\n",
    "mean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "# colors =  [\"#E13F29\", \"#D69A80\", \"#D63B59\", \"#AE5552\", \"#CB5C3B\", \"#EB8076\", \"#96624E\"]\n",
    "# ax = mean.plot(kind=\"hist\", figsize=(5,5), autopct='%1.1f%%', colors = colors, fontsize=12)\n",
    "ax = mean.plot(kind=\"hist\", figsize=(4,2.5), rot=0, color = \"grey\", bins=10, fontsize=12)\n",
    "seaborn.despine(right=True)\n",
    "plt.xlabel(xlabel=\"Fraction\", fontsize=12)\n",
    "plt.ylabel(ylabel=\"Count\", fontsize=12)\n",
    "# plt.yticks([0, 100000, 200000, 300000])\n",
    "# ax.legend(loc = 0, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('frac.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27766330837096104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import gmean\n",
    "import numpy as np\n",
    "np.mean(pre[\"leak_lengths\"].explode()), np.mean(pre[\"file_length\"])\n",
    "np.mean(pre[\"frac\"].explode().to_numpy().astype(float))\n",
    "# pre[\"frac\"].explode().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99779</th>\n",
       "      <td>4397</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99781</th>\n",
       "      <td>4399</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99800</th>\n",
       "      <td>4418</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99824</th>\n",
       "      <td>4446</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99834</th>\n",
       "      <td>4456</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18437 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb  \\\n",
       "0               0  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "2               2  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "7               7  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "16             17  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "34             35  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "...           ...                                                ...   \n",
       "99779        4397  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99781        4399  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99800        4418  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99824        4446  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99834        4456  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "\n",
       "            msg  train  val  test  model  pre  overlap  multi  \n",
       "0      Success!      3    3     2      3  198        0   True  \n",
       "2      Success!      5    5     0      5    5        0   True  \n",
       "7      Success!      8   19     1      7    0        7   True  \n",
       "16     Success!      6   13     2      4    0        0   True  \n",
       "34     Success!     13    8     5      9    0        9   True  \n",
       "...         ...    ...  ...   ...    ...  ...      ...    ...  \n",
       "99779  Success!      4    5     0      5   10        0   True  \n",
       "99781  Success!      1    3     0      1    0        0   True  \n",
       "99800  Success!      5    5     0      5   10        0   True  \n",
       "99824  Success!      4   16     0      4   24        0   True  \n",
       "99834  Success!     12   18     0     12  128        0   True  \n",
       "\n",
       "[18437 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = data[data[\"multi\"]]\n",
    "multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/cyang3/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/tmp/ipykernel_3605/2412548977.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi['file_length'] = multi['nb'].map(lambda x: len(open(x).read().splitlines()))\n"
     ]
    }
   ],
   "source": [
    "def find_results(row):\n",
    "    file_path = row['nb']\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    multi_leaks = os.path.join(file_path, \"Telemetry_MultiUseTestLeak.csv\")\n",
    "    involoc = os.path.join(file_path, \"InvokeLineno.facts\")\n",
    "    lineno = os.path.join(file_path, \"LinenoMapping.facts\")\n",
    "\n",
    "    multi_df = pd.read_csv(multi_leaks, sep=\"\\t\", names=['testModel', 'test', 'invo', 'meth', 'ctx1', 'testModel2', 'test2', 'invo2', 'meth2', 'ctx2'])\n",
    "    \n",
    "    involoc = pd.read_csv(involoc, sep=\"\\t\", names=['invo', 'line']).set_index('invo').squeeze().to_dict()\n",
    "    lineno_map = pd.read_csv(lineno, sep=\"\\t\", names=['line', 'line_o']).set_index('line').squeeze().to_dict()\n",
    "    def get_diff(row):\n",
    "        try:\n",
    "            return abs(lineno_map[involoc[row['invo']]] - lineno_map[involoc[row['invo2']]])\n",
    "        except KeyError:\n",
    "            return -1\n",
    "    diff = multi_df[['invo', 'invo2']].apply(get_diff, axis=1)\n",
    "    \n",
    "    return {\"leak_lengths\": diff[diff >= 0].to_list(), \"cnt\": multi_df[\"invo\"].nunique()}\n",
    "\n",
    "multi[['leak_lengths', 'cnt']] = multi.apply(find_results, axis=1, result_type='expand')\n",
    "multi['file_length'] = multi['nb'].map(lambda x: len(open(x).read().splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "      <th>leak_lengths</th>\n",
       "      <th>cnt</th>\n",
       "      <th>file_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[55, 74, 55, 19, 74, 19]</td>\n",
       "      <td>3</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>[37, 54, 94, 36, 53, 93, 30, 47, 87, 24, 41, 8...</td>\n",
       "      <td>13</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[453, 451, 379, 104, 453, 451, 379, 104, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99779</th>\n",
       "      <td>4397</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99781</th>\n",
       "      <td>4399</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99800</th>\n",
       "      <td>4418</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[28, 91, 157, 222, 28, 63, 129, 194, 91, 63, 6...</td>\n",
       "      <td>5</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99824</th>\n",
       "      <td>4446</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[62, 71, 125, 134, 185, 194, 53, 62, 116, 125,...</td>\n",
       "      <td>8</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99834</th>\n",
       "      <td>4456</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[23, 23, 10, 10, 10, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18437 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb  \\\n",
       "0               0  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "2               2  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "7               7  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "16             17  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "34             35  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "...           ...                                                ...   \n",
       "99779        4397  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99781        4399  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99800        4418  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99824        4446  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99834        4456  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "\n",
       "            msg  train  val  test  model  pre  overlap  multi  \\\n",
       "0      Success!      3    3     2      3  198        0   True   \n",
       "2      Success!      5    5     0      5    5        0   True   \n",
       "7      Success!      8   19     1      7    0        7   True   \n",
       "16     Success!      6   13     2      4    0        0   True   \n",
       "34     Success!     13    8     5      9    0        9   True   \n",
       "...         ...    ...  ...   ...    ...  ...      ...    ...   \n",
       "99779  Success!      4    5     0      5   10        0   True   \n",
       "99781  Success!      1    3     0      1    0        0   True   \n",
       "99800  Success!      5    5     0      5   10        0   True   \n",
       "99824  Success!      4   16     0      4   24        0   True   \n",
       "99834  Success!     12   18     0     12  128        0   True   \n",
       "\n",
       "                                            leak_lengths  cnt  file_length  \n",
       "0                               [55, 74, 55, 19, 74, 19]    3         1063  \n",
       "2                                                     []    0          451  \n",
       "7      [37, 54, 94, 36, 53, 93, 30, 47, 87, 24, 41, 8...   13         1807  \n",
       "16           [453, 451, 379, 104, 453, 451, 379, 104, 0]    5         1818  \n",
       "34                                                    []    0          488  \n",
       "...                                                  ...  ...          ...  \n",
       "99779                                                 []    0          557  \n",
       "99781                                                 []    0          350  \n",
       "99800  [28, 91, 157, 222, 28, 63, 129, 194, 91, 63, 6...    5          417  \n",
       "99824  [62, 71, 125, 134, 185, 194, 53, 62, 116, 125,...    8          482  \n",
       "99834                           [23, 23, 10, 10, 10, 10]    6         1066  \n",
       "\n",
       "[18437 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3605/4030348879.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multi[\"frac\"] = multi.apply(lambda l: [x/l[\"file_length\"] for x in l[\"leak_lengths\"]], axis=1)\n"
     ]
    }
   ],
   "source": [
    "multi[\"frac\"] = multi.apply(lambda l: [x/l[\"file_length\"] for x in l[\"leak_lengths\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.418397787058632"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import gmean\n",
    "import numpy as np\n",
    "np.mean(multi[\"leak_lengths\"].explode()), np.mean(multi[\"file_length\"])\n",
    "np.mean(multi[\"frac\"].explode().to_numpy().astype(float))\n",
    "multi[\"frac\"].explode().mean()\n",
    "multi[\"cnt\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "ax = multi[\"frac\"].explode().plot(kind=\"hist\", figsize=(4,2.5), rot=0, color = \"grey\", bins=10, fontsize=12)\n",
    "seaborn.despine(right=True)\n",
    "plt.xlabel(xlabel=\"Fraction\", fontsize=12)\n",
    "plt.ylabel(ylabel=\"Count\", fontsize=12)\n",
    "# plt.yticks([0, 100000, 200000, 300000])\n",
    "# ax.legend(loc = 0, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('frac2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>70</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99634</th>\n",
       "      <td>4230</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99711</th>\n",
       "      <td>4324</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>4325</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99715</th>\n",
       "      <td>4328</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99815</th>\n",
       "      <td>4435</td>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6462 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 nb  \\\n",
       "7               7  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "25             26  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "33             34  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "34             35  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "65             70  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "...           ...                                                ...   \n",
       "99634        4230  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99711        4324  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99712        4325  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99715        4328  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "99815        4435  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...   \n",
       "\n",
       "            msg  train  val  test  model  pre  overlap  multi  \n",
       "7      Success!      8   19     1      7    0        7   True  \n",
       "25     Success!      1    0     1      1    0        1  False  \n",
       "33     Success!      6    0    12      6    0        6  False  \n",
       "34     Success!     13    8     5      9    0        9   True  \n",
       "65     Success!      1    0     1      1    0        1  False  \n",
       "...         ...    ...  ...   ...    ...  ...      ...    ...  \n",
       "99634  Success!     16   20     0     45    0        2   True  \n",
       "99711  Success!      1    0     3      1    0        1  False  \n",
       "99712  Success!      1    0     3      1    0        1  False  \n",
       "99715  Success!      1    0     4      1    0        1  False  \n",
       "99815  Success!      1    2     1      1    0        1  False  \n",
       "\n",
       "[6462 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over = data[data[\"overlap\"] > 0]\n",
    "over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2770973/1720723058.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  over['length'] = over['nb'].map(find_results)\n"
     ]
    }
   ],
   "source": [
    "def find_results(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    over_leaks = os.path.join(file_path, \"Telemetry_OverlapLeak.csv\")\n",
    "    involoc = os.path.join(file_path, \"InvokeLineno.facts\")\n",
    "\n",
    "    over = pd.read_csv(over_leaks, sep=\"\\t\", names=['trainModel', 'train', 'trainInvo', 'trainMeth', 'ctx1', 'testModel', 'test', 'invo', 'testMeth', 'ctx2'])\n",
    "    \n",
    "    involoc = pd.read_csv(involoc, sep=\"\\t\", names=['invo', 'line']).set_index('invo').squeeze().to_dict()\n",
    "    def get_diff(row):\n",
    "        return abs(involoc[row['invo']] - involoc[row['trainInvo']])\n",
    "    diff = over[['trainInvo', 'invo']].apply(get_diff, axis=1)\n",
    "    return diff.to_list()\n",
    "over['length'] = over['nb'].map(find_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over['length'].explode().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2926260/271190908.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  star[\"nb\"] = star[\"nb\"].str.replace(\".ipynb\", \".py\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/leak_info.txt\")\n",
    "star = pd.read_csv(\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/nbstar.txt\", sep=\"\\t\", names=[\"nb\", \"star\"])\n",
    "star[\"nb\"] = star[\"nb\"].str.replace(\".ipynb\", \".py\")\n",
    "data = data.merge(star, on=\"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"leak\"] = (data[\"pre\"]  > 0) | (data[\"overlap\"]  > 0) | data[\"multi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"star\"] = pd.qcut(data[\"star\"], 200, duplicates=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 1.0]     93808\n",
       "(1.0, 2.0]         1639\n",
       "(3.0, 4.0]         1184\n",
       "(2.0, 3.0]          906\n",
       "(4.0, 6.0]          607\n",
       "(6.0, 9.0]          483\n",
       "(18.0, 2229.0]      480\n",
       "(9.0, 18.0]         378\n",
       "Name: star, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"star\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4182958443558743, 0.3023802636947647)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend = data.groupby(\"star\")[\"leak\"].apply(lambda x: sum(x)/len(x))\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "t = list(x.right for x in trend.index)\n",
    "pearsonr(t, trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (-0.001, 1.0]\n",
       "1        (-0.001, 1.0]\n",
       "2        (-0.001, 1.0]\n",
       "3        (-0.001, 1.0]\n",
       "4        (-0.001, 1.0]\n",
       "             ...      \n",
       "99480    (-0.001, 1.0]\n",
       "99481    (-0.001, 1.0]\n",
       "99482    (-0.001, 1.0]\n",
       "99483    (-0.001, 1.0]\n",
       "99484    (-0.001, 1.0]\n",
       "Name: star, Length: 99485, dtype: category\n",
       "Categories (4, interval[float64, right]): [(-0.001, 1.0] < (1.0, 3.0] < (3.0, 4.0] < (4.0, 2229.0]]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(data[\"star\"], 50, duplicates=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (1, 3), (4, 6), (7, 9), (10, 100000)],\n",
       " [29.88660048751192,\n",
       "  28.350244926522045,\n",
       "  31.60245672808487,\n",
       "  17.391304347826086,\n",
       "  20.862470862470865])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounds = [(i, i) for i in range(0, 21,1)] + [(21,100000)]\n",
    "bounds = [(0,0), (1, 3), (4,6), (7,9), (10, 100000)]\n",
    "mean = []\n",
    "for st,ed in bounds:\n",
    "    d = data[(data[\"star\"] >= st) & (data[\"star\"] <= ed)]\n",
    "    mean.append(len(d[(d[\"pre\"]  > 0) | (d[\"overlap\"]  > 0) | d[\"multi\"]]) /len(d) * 100)\n",
    "bounds, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "mean = pd.Series(mean, index=[\"0\", \"1-3\", \"4-6\", \"7-9\", \"10+\"])\n",
    "ax = mean.plot(kind='bar', figsize=(4,2.5), color=['grey'], rot=0, fontsize=12)\n",
    "seaborn.despine(right=True)\n",
    "plt.ylabel(ylabel=\"Percentage (%)\", fontsize=12)\n",
    "plt.yticks([0, 5, 10, 15, 20, 25, 30, 35, 40])\n",
    "# ax.legend(loc = 1, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('stars.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating HTML Page to Track Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0389363722697056,\n",
       " 0.029439696106362774,\n",
       " 0.11301044634377967,\n",
       " 0.1623931623931624)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass = pd.read_csv(\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/tutorial.txt\", names=[\"nb\"])\n",
    "ass = ass.merge(data, on=\"nb\")\n",
    "f_ass = ass[(ass[\"pre\"]  > 0) | (ass[\"overlap\"]  > 0) | (ass[\"multi\"])]\n",
    "len(ass[ass[\"pre\"]  > 0]) /len(ass), len(ass[ass[\"overlap\"]  > 0]) /len(ass), len(ass[ass[\"multi\"]]) /len(ass), \\\n",
    "    len(ass[(ass[\"pre\"]  > 0) | (ass[\"overlap\"]  > 0) | ass[\"multi\"]]) /len(ass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f_ass\n",
    "nb_ref = []\n",
    "tags = [\"pre\", \"overlap\", \"multi\"]\n",
    "for i, row in df.iterrows():\n",
    "    nb = row[\"nb\"]\n",
    "    nb = \"/\".join(nb.split(\"/\")[1:]).replace(\".py\", \".html\")\n",
    "    row_tags = [tag for tag in tags if row[tag]>0]\n",
    "    nb_ref.append(f'<li><a href=\"{nb}\">{nb}</a>, {\", \".join(row_tags)}</li>')\n",
    "refs = '\\n'.join(nb_ref)\n",
    "html_page = f'''<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "<title>Directory listing for /</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Directory listing for /</h1>\n",
    "<hr>\n",
    "<ul>\n",
    "{refs}\n",
    "</ul>\n",
    "<hr>\n",
    "</body>\n",
    "</html>'''\n",
    "with open(\"tutorial-leaks.html\", \"w\") as f:\n",
    "    f.write(html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n<title>Directory listing for /</title>\\n</head>\\n<body>\\n<h1>Directory listing for /</h1>\\n<hr>\\n<ul>\\n<li><a href=\"notebooks/2021-09-01/nb_197.html\">notebooks/2021-09-01/nb_197.html</a></li>\\n<li><a href=\"notebooks/2021-09-01/nb_556.html\">notebooks/2021-09-01/nb_556.html</a></li>\\n<li><a href=\"notebooks/2021-09-01/nb_1279.html\">notebooks/2021-09-01/nb_1279.html</a></li>\\n<li><a href=\"notebooks/2021-09-01/nb_1280.html\">notebooks/2021-09-01/nb_1280.html</a></li>\\n<li><a href=\"notebooks/2021-09-01/nb_2596.html\">notebooks/2021-09-01/nb_2596.html</a></li>\\n<li><a href=\"notebooks/2021-09-01/nb_2610.html\">notebooks/2021-09-01/nb_2610.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_132.html\">notebooks/2021-09-02/nb_132.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_897.html\">notebooks/2021-09-02/nb_897.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_1354.html\">notebooks/2021-09-02/nb_1354.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_1387.html\">notebooks/2021-09-02/nb_1387.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_2539.html\">notebooks/2021-09-02/nb_2539.html</a></li>\\n<li><a href=\"notebooks/2021-09-02/nb_3686.html\">notebooks/2021-09-02/nb_3686.html</a></li>\\n<li><a href=\"notebooks/2021-09-03/nb_591.html\">notebooks/2021-09-03/nb_591.html</a></li>\\n<li><a href=\"notebooks/2021-09-03/nb_2622.html\">notebooks/2021-09-03/nb_2622.html</a></li>\\n<li><a href=\"notebooks/2021-09-03/nb_3527.html\">notebooks/2021-09-03/nb_3527.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_216.html\">notebooks/2021-09-04/nb_216.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_218.html\">notebooks/2021-09-04/nb_218.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_219.html\">notebooks/2021-09-04/nb_219.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_225.html\">notebooks/2021-09-04/nb_225.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_867.html\">notebooks/2021-09-04/nb_867.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_879.html\">notebooks/2021-09-04/nb_879.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_880.html\">notebooks/2021-09-04/nb_880.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_882.html\">notebooks/2021-09-04/nb_882.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_883.html\">notebooks/2021-09-04/nb_883.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_884.html\">notebooks/2021-09-04/nb_884.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_886.html\">notebooks/2021-09-04/nb_886.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_887.html\">notebooks/2021-09-04/nb_887.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_888.html\">notebooks/2021-09-04/nb_888.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_889.html\">notebooks/2021-09-04/nb_889.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_890.html\">notebooks/2021-09-04/nb_890.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_893.html\">notebooks/2021-09-04/nb_893.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_894.html\">notebooks/2021-09-04/nb_894.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_895.html\">notebooks/2021-09-04/nb_895.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_896.html\">notebooks/2021-09-04/nb_896.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_968.html\">notebooks/2021-09-04/nb_968.html</a></li>\\n<li><a href=\"notebooks/2021-09-04/nb_2769.html\">notebooks/2021-09-04/nb_2769.html</a></li>\\n<li><a href=\"notebooks/2021-09-05/nb_304.html\">notebooks/2021-09-05/nb_304.html</a></li>\\n<li><a href=\"notebooks/2021-09-05/nb_2365.html\">notebooks/2021-09-05/nb_2365.html</a></li>\\n<li><a href=\"notebooks/2021-09-05/nb_2366.html\">notebooks/2021-09-05/nb_2366.html</a></li>\\n<li><a href=\"notebooks/2021-09-05/nb_2944.html\">notebooks/2021-09-05/nb_2944.html</a></li>\\n<li><a href=\"notebooks/2021-09-05/nb_3100.html\">notebooks/2021-09-05/nb_3100.html</a></li>\\n<li><a href=\"notebooks/2021-09-06/nb_161.html\">notebooks/2021-09-06/nb_161.html</a></li>\\n<li><a href=\"notebooks/2021-09-06/nb_491.html\">notebooks/2021-09-06/nb_491.html</a></li>\\n<li><a href=\"notebooks/2021-09-06/nb_1030.html\">notebooks/2021-09-06/nb_1030.html</a></li>\\n<li><a href=\"notebooks/2021-09-06/nb_2880.html\">notebooks/2021-09-06/nb_2880.html</a></li>\\n<li><a href=\"notebooks/2021-09-06/nb_3030.html\">notebooks/2021-09-06/nb_3030.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_161.html\">notebooks/2021-09-07/nb_161.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_162.html\">notebooks/2021-09-07/nb_162.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_1129.html\">notebooks/2021-09-07/nb_1129.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_1695.html\">notebooks/2021-09-07/nb_1695.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_1761.html\">notebooks/2021-09-07/nb_1761.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_2607.html\">notebooks/2021-09-07/nb_2607.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_2608.html\">notebooks/2021-09-07/nb_2608.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_2619.html\">notebooks/2021-09-07/nb_2619.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_2627.html\">notebooks/2021-09-07/nb_2627.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_3049.html\">notebooks/2021-09-07/nb_3049.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_3479.html\">notebooks/2021-09-07/nb_3479.html</a></li>\\n<li><a href=\"notebooks/2021-09-07/nb_3843.html\">notebooks/2021-09-07/nb_3843.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_79.html\">notebooks/2021-09-08/nb_79.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_729.html\">notebooks/2021-09-08/nb_729.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_2330.html\">notebooks/2021-09-08/nb_2330.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_2346.html\">notebooks/2021-09-08/nb_2346.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_2876.html\">notebooks/2021-09-08/nb_2876.html</a></li>\\n<li><a href=\"notebooks/2021-09-08/nb_2957.html\">notebooks/2021-09-08/nb_2957.html</a></li>\\n<li><a href=\"notebooks/2021-09-09/nb_771.html\">notebooks/2021-09-09/nb_771.html</a></li>\\n<li><a href=\"notebooks/2021-09-09/nb_772.html\">notebooks/2021-09-09/nb_772.html</a></li>\\n<li><a href=\"notebooks/2021-09-09/nb_2880.html\">notebooks/2021-09-09/nb_2880.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_27.html\">notebooks/2021-09-10/nb_27.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_72.html\">notebooks/2021-09-10/nb_72.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_154.html\">notebooks/2021-09-10/nb_154.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_170.html\">notebooks/2021-09-10/nb_170.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_321.html\">notebooks/2021-09-10/nb_321.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_1325.html\">notebooks/2021-09-10/nb_1325.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_2604.html\">notebooks/2021-09-10/nb_2604.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_2699.html\">notebooks/2021-09-10/nb_2699.html</a></li>\\n<li><a href=\"notebooks/2021-09-10/nb_2700.html\">notebooks/2021-09-10/nb_2700.html</a></li>\\n<li><a href=\"notebooks/2021-09-12/nb_3065.html\">notebooks/2021-09-12/nb_3065.html</a></li>\\n<li><a href=\"notebooks/2021-09-12/nb_3066.html\">notebooks/2021-09-12/nb_3066.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_172.html\">notebooks/2021-09-13/nb_172.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_271.html\">notebooks/2021-09-13/nb_271.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_918.html\">notebooks/2021-09-13/nb_918.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_948.html\">notebooks/2021-09-13/nb_948.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_1717.html\">notebooks/2021-09-13/nb_1717.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_2097.html\">notebooks/2021-09-13/nb_2097.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_2535.html\">notebooks/2021-09-13/nb_2535.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_3186.html\">notebooks/2021-09-13/nb_3186.html</a></li>\\n<li><a href=\"notebooks/2021-09-13/nb_3450.html\">notebooks/2021-09-13/nb_3450.html</a></li>\\n<li><a href=\"notebooks/2021-09-14/nb_1355.html\">notebooks/2021-09-14/nb_1355.html</a></li>\\n<li><a href=\"notebooks/2021-09-15/nb_817.html\">notebooks/2021-09-15/nb_817.html</a></li>\\n<li><a href=\"notebooks/2021-09-15/nb_3377.html\">notebooks/2021-09-15/nb_3377.html</a></li>\\n<li><a href=\"notebooks/2021-09-16/nb_1244.html\">notebooks/2021-09-16/nb_1244.html</a></li>\\n<li><a href=\"notebooks/2021-09-16/nb_2627.html\">notebooks/2021-09-16/nb_2627.html</a></li>\\n<li><a href=\"notebooks/2021-09-16/nb_3371.html\">notebooks/2021-09-16/nb_3371.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_306.html\">notebooks/2021-09-17/nb_306.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_307.html\">notebooks/2021-09-17/nb_307.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_1002.html\">notebooks/2021-09-17/nb_1002.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_1011.html\">notebooks/2021-09-17/nb_1011.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_1106.html\">notebooks/2021-09-17/nb_1106.html</a></li>\\n<li><a href=\"notebooks/2021-09-17/nb_3749.html\">notebooks/2021-09-17/nb_3749.html</a></li>\\n<li><a href=\"notebooks/2021-09-18/nb_605.html\">notebooks/2021-09-18/nb_605.html</a></li>\\n<li><a href=\"notebooks/2021-09-18/nb_770.html\">notebooks/2021-09-18/nb_770.html</a></li>\\n<li><a href=\"notebooks/2021-09-19/nb_1024.html\">notebooks/2021-09-19/nb_1024.html</a></li>\\n<li><a href=\"notebooks/2021-09-19/nb_1250.html\">notebooks/2021-09-19/nb_1250.html</a></li>\\n<li><a href=\"notebooks/2021-09-19/nb_2744.html\">notebooks/2021-09-19/nb_2744.html</a></li>\\n<li><a href=\"notebooks/2021-09-19/nb_2746.html\">notebooks/2021-09-19/nb_2746.html</a></li>\\n<li><a href=\"notebooks/2021-09-20/nb_769.html\">notebooks/2021-09-20/nb_769.html</a></li>\\n<li><a href=\"notebooks/2021-09-20/nb_1482.html\">notebooks/2021-09-20/nb_1482.html</a></li>\\n<li><a href=\"notebooks/2021-09-20/nb_2135.html\">notebooks/2021-09-20/nb_2135.html</a></li>\\n<li><a href=\"notebooks/2021-09-20/nb_2802.html\">notebooks/2021-09-20/nb_2802.html</a></li>\\n<li><a href=\"notebooks/2021-09-20/nb_3213.html\">notebooks/2021-09-20/nb_3213.html</a></li>\\n<li><a href=\"notebooks/2021-09-21/nb_461.html\">notebooks/2021-09-21/nb_461.html</a></li>\\n<li><a href=\"notebooks/2021-09-21/nb_1131.html\">notebooks/2021-09-21/nb_1131.html</a></li>\\n<li><a href=\"notebooks/2021-09-21/nb_1799.html\">notebooks/2021-09-21/nb_1799.html</a></li>\\n<li><a href=\"notebooks/2021-09-21/nb_1868.html\">notebooks/2021-09-21/nb_1868.html</a></li>\\n<li><a href=\"notebooks/2021-09-21/nb_1869.html\">notebooks/2021-09-21/nb_1869.html</a></li>\\n<li><a href=\"notebooks/2021-09-22/nb_588.html\">notebooks/2021-09-22/nb_588.html</a></li>\\n<li><a href=\"notebooks/2021-09-22/nb_954.html\">notebooks/2021-09-22/nb_954.html</a></li>\\n<li><a href=\"notebooks/2021-09-22/nb_3111.html\">notebooks/2021-09-22/nb_3111.html</a></li>\\n<li><a href=\"notebooks/2021-09-22/nb_3112.html\">notebooks/2021-09-22/nb_3112.html</a></li>\\n<li><a href=\"notebooks/2021-09-23/nb_306.html\">notebooks/2021-09-23/nb_306.html</a></li>\\n<li><a href=\"notebooks/2021-09-23/nb_832.html\">notebooks/2021-09-23/nb_832.html</a></li>\\n<li><a href=\"notebooks/2021-09-23/nb_1282.html\">notebooks/2021-09-23/nb_1282.html</a></li>\\n<li><a href=\"notebooks/2021-09-23/nb_2326.html\">notebooks/2021-09-23/nb_2326.html</a></li>\\n<li><a href=\"notebooks/2021-09-23/nb_3042.html\">notebooks/2021-09-23/nb_3042.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_472.html\">notebooks/2021-09-24/nb_472.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_833.html\">notebooks/2021-09-24/nb_833.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_834.html\">notebooks/2021-09-24/nb_834.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_835.html\">notebooks/2021-09-24/nb_835.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_836.html\">notebooks/2021-09-24/nb_836.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_1051.html\">notebooks/2021-09-24/nb_1051.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_1759.html\">notebooks/2021-09-24/nb_1759.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_1769.html\">notebooks/2021-09-24/nb_1769.html</a></li>\\n<li><a href=\"notebooks/2021-09-24/nb_1932.html\">notebooks/2021-09-24/nb_1932.html</a></li>\\n<li><a href=\"notebooks/2021-09-25/nb_252.html\">notebooks/2021-09-25/nb_252.html</a></li>\\n<li><a href=\"notebooks/2021-09-27/nb_3227.html\">notebooks/2021-09-27/nb_3227.html</a></li>\\n<li><a href=\"notebooks/2021-09-27/nb_4231.html\">notebooks/2021-09-27/nb_4231.html</a></li>\\n<li><a href=\"notebooks/2021-09-27/nb_4299.html\">notebooks/2021-09-27/nb_4299.html</a></li>\\n<li><a href=\"notebooks/2021-09-27/nb_4835.html\">notebooks/2021-09-27/nb_4835.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_784.html\">notebooks/2021-09-28/nb_784.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_1475.html\">notebooks/2021-09-28/nb_1475.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2057.html\">notebooks/2021-09-28/nb_2057.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2218.html\">notebooks/2021-09-28/nb_2218.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2223.html\">notebooks/2021-09-28/nb_2223.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2522.html\">notebooks/2021-09-28/nb_2522.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2770.html\">notebooks/2021-09-28/nb_2770.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_2840.html\">notebooks/2021-09-28/nb_2840.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_3964.html\">notebooks/2021-09-28/nb_3964.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4127.html\">notebooks/2021-09-28/nb_4127.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4128.html\">notebooks/2021-09-28/nb_4128.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4129.html\">notebooks/2021-09-28/nb_4129.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4130.html\">notebooks/2021-09-28/nb_4130.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4131.html\">notebooks/2021-09-28/nb_4131.html</a></li>\\n<li><a href=\"notebooks/2021-09-28/nb_4133.html\">notebooks/2021-09-28/nb_4133.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_186.html\">notebooks/2021-09-29/nb_186.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_187.html\">notebooks/2021-09-29/nb_187.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_190.html\">notebooks/2021-09-29/nb_190.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_191.html\">notebooks/2021-09-29/nb_191.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_192.html\">notebooks/2021-09-29/nb_192.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_193.html\">notebooks/2021-09-29/nb_193.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_1955.html\">notebooks/2021-09-29/nb_1955.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_2911.html\">notebooks/2021-09-29/nb_2911.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_3794.html\">notebooks/2021-09-29/nb_3794.html</a></li>\\n<li><a href=\"notebooks/2021-09-29/nb_3873.html\">notebooks/2021-09-29/nb_3873.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_589.html\">notebooks/2021-09-30/nb_589.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_1357.html\">notebooks/2021-09-30/nb_1357.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_2326.html\">notebooks/2021-09-30/nb_2326.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_2531.html\">notebooks/2021-09-30/nb_2531.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_2799.html\">notebooks/2021-09-30/nb_2799.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_3004.html\">notebooks/2021-09-30/nb_3004.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_3812.html\">notebooks/2021-09-30/nb_3812.html</a></li>\\n<li><a href=\"notebooks/2021-09-30/nb_3819.html\">notebooks/2021-09-30/nb_3819.html</a></li>\\n</ul>\\n<hr>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"tutorial-leak.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", index_col=False, names=[\"nb\"])\n",
    "nb_ref = []\n",
    "for nb in df[\"nb\"]:\n",
    "    nb = \"/\".join(nb.split(\"/\")[1:]).replace(\".py\", \".html\")\n",
    "    nb_ref.append(f'<li><a href=\"{nb}\">{nb}</a></li>')\n",
    "refs = '\\n'.join(nb_ref)\n",
    "html_page = f'''<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "<title>Directory listing for /</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Directory listing for /</h1>\n",
    "<hr>\n",
    "<ul>\n",
    "{refs}\n",
    "</ul>\n",
    "<hr>\n",
    "</body>\n",
    "</html>'''\n",
    "# with open(\"tutorial-leaks.html\", \"w\") as f:\n",
    "#     f.write(html_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Samples for Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>msg</th>\n",
       "      <th>model</th>\n",
       "      <th>pre</th>\n",
       "      <th>overlap</th>\n",
       "      <th>multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>../../GitHubAPI-Crawler/GitHub-data/notebooks/...</td>\n",
       "      <td>Success!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nb       msg  model  \\\n",
       "0    ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "1    ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "2    ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "3    ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "4    ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "..                                                 ...       ...    ...   \n",
       "103  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "104  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "105  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "106  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!   True   \n",
       "107  ../../GitHubAPI-Crawler/GitHub-data/notebooks/...  Success!  False   \n",
       "\n",
       "       pre  overlap  multi  \n",
       "0    False    False  False  \n",
       "1     True    False  False  \n",
       "2    False    False  False  \n",
       "3     True    False  False  \n",
       "4    False    False  False  \n",
       "..     ...      ...    ...  \n",
       "103  False    False  False  \n",
       "104  False    False  False  \n",
       "105  False     True   True  \n",
       "106  False    False  False  \n",
       "107  False    False  False  \n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze sample log\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "file_path = \"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/sample.txt-log.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", index_col=False, names=[\"nb\", \"msg\", \"t1\", \"t2\", \"t3\", \"t\"])\n",
    "df = df[[\"nb\", \"msg\"]]\n",
    "df[\"nb\"] = df[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", x))\n",
    "df = df[df[\"msg\"] == \"Success!\"]\n",
    "def find_results(file_path):\n",
    "    file_path = file_path.replace(\".py\", \"-fact\")\n",
    "    model_pairs = os.path.join(file_path, \"ModelPair.csv\")\n",
    "    pre_leaks = os.path.join(file_path, \"Telemetry_FinalPreProcessingLeak.csv\")\n",
    "    overlap_leaks = os.path.join(file_path, \"FinalOverlapLeak.csv\")\n",
    "    multi_leaks = os.path.join(file_path, \"FinalNoTestDataWithMultiUse.csv\")\n",
    "    has_pairs = len(open(model_pairs).read().splitlines()) > 0\n",
    "    has_pre_leaks = len(open(pre_leaks).read().splitlines()) > 0\n",
    "    has_overlap_leaks = len(open(overlap_leaks).read().splitlines()) > 0\n",
    "    has_multi_leaks = len(open(multi_leaks).read().splitlines()) > 0\n",
    "    return {\"model\": has_pairs, \"pre\": has_pre_leaks, \"overlap\": has_overlap_leaks, \"multi\": has_multi_leaks}\n",
    "# df.merge(df[\"nb\"].map(find_results), left_index=True, right_index=True)\n",
    "applied_df = df.apply(lambda row: find_results(row[\"nb\"]), axis='columns', result_type='expand')\n",
    "df = pd.concat([df, applied_df], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2770973/1827310437.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(merged[merged[f\"model_y\"] == True][merged[f\"{col}_x\"] != merged[f\"{col}_y\"]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"/usr0/home/cyang3/Projects/GitHubAPI-Crawler/GitHub-data/manual-labels.csv\")\n",
    "def translate(x:str):\n",
    "    return str(x).startswith(\"Y\")\n",
    "df2 = df2[['nb', 'model', 'pre', 'overlap', 'multi']]\n",
    "df2[\"nb\"] = df2[\"nb\"].map(lambda x: os.path.join(\"..\", \"..\", \"GitHubAPI-Crawler\", x))\n",
    "columns = ['model', 'pre', 'overlap', 'multi']\n",
    "for col in columns:\n",
    "    df2[col] = df2[col].map(translate)\n",
    "merged = df2.merge(df, on=\"nb\")\n",
    "merged[\"nb\"] = merged[\"nb\"].map(lambda x: '/'.join(x.split('/')[-2:]))\n",
    "col = \"multi\"\n",
    "# merged[merged[f\"model_x\"] == merged[f\"model_y\"]][merged[f\"multi_x\"] == merged[f\"multi_y\"]][merged[f\"pre_x\"] == merged[f\"pre_y\"]][merged[f\"overlap_x\"] == merged[f\"overlap_y\"]]\n",
    "len(merged[merged[f\"model_y\"] == True][merged[f\"{col}_x\"] != merged[f\"{col}_y\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-17/nb_1782.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-30/nb_195.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-01/nb_604.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-10/nb_2760.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-10/nb_322.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-27/nb_3449.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-05/nb_2816.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-30/nb_3594.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-15/nb_281.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-05/nb_1162.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-05/nb_2770.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-30/nb_89.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-05/nb_773.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-20/nb_1743.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-30/nb_3336.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-05/nb_1630.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-13/nb_3144.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-30/nb_619.py',\n",
       " '../../GitHubAPI-Crawler/GitHub-data/notebooks/2021-09-03/nb_2630.py']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"multi\"] == True])\n",
    "df[df[\"multi\"]][\"nb\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df = pd.read_csv(\"../tmp/log-03-28.txt\", sep=\"/\", names=[\"pp\", \"p\", \"c\", \"n\", \"date\", \"file\", \"label\"])\n",
    "df[\"file\"] = df[\"file\"].str.replace(\"-fact\", \".py\")\n",
    "files = df.groupby(\"label\")[\"file\"].apply(list).map(lambda x: sorted(random.sample(x, 20), key=lambda x:int(x[3:-3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_119.py',\n",
       " 'nb_216.py',\n",
       " 'nb_353.py',\n",
       " 'nb_359.py',\n",
       " 'nb_645.py',\n",
       " 'nb_701.py',\n",
       " 'nb_798.py',\n",
       " 'nb_886.py',\n",
       " 'nb_906.py',\n",
       " 'nb_1084.py',\n",
       " 'nb_1147.py',\n",
       " 'nb_1243.py',\n",
       " 'nb_1386.py',\n",
       " 'nb_1524.py',\n",
       " 'nb_1643.py',\n",
       " 'nb_1949.py',\n",
       " 'nb_2125.py',\n",
       " 'nb_2132.py',\n",
       " 'nb_2387.py',\n",
       " 'nb_3125.py']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3,\n",
       " 10,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 25,\n",
       " 70,\n",
       " 71,\n",
       " 91,\n",
       " 97,\n",
       " 106,\n",
       " 126,\n",
       " 144,\n",
       " 145,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 160,\n",
       " 165,\n",
       " 178,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 187,\n",
       " 190,\n",
       " 192,\n",
       " 193,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 203,\n",
       " 208,\n",
       " 220,\n",
       " 225,\n",
       " 226,\n",
       " 239,\n",
       " 243,\n",
       " 255,\n",
       " 257,\n",
       " 264,\n",
       " 265,\n",
       " 267,\n",
       " 269,\n",
       " 277,\n",
       " 279,\n",
       " 285,\n",
       " 293,\n",
       " 297,\n",
       " 304,\n",
       " 306,\n",
       " 308,\n",
       " 319,\n",
       " 324,\n",
       " 325,\n",
       " 329,\n",
       " 332,\n",
       " 333,\n",
       " 343,\n",
       " 344,\n",
       " 349,\n",
       " 353,\n",
       " 360,\n",
       " 365,\n",
       " 380,\n",
       " 383,\n",
       " 385,\n",
       " 387,\n",
       " 388,\n",
       " 394,\n",
       " 406,\n",
       " 422,\n",
       " 437,\n",
       " 438,\n",
       " 441,\n",
       " 449,\n",
       " 450,\n",
       " 452,\n",
       " 456,\n",
       " 457,\n",
       " 463,\n",
       " 464,\n",
       " 474,\n",
       " 479,\n",
       " 481,\n",
       " 485,\n",
       " 495,\n",
       " 496,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 503,\n",
       " 504,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 510,\n",
       " 513,\n",
       " 515,\n",
       " 521,\n",
       " 522,\n",
       " 525,\n",
       " 535,\n",
       " 539,\n",
       " 549,\n",
       " 555,\n",
       " 565,\n",
       " 568,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 591,\n",
       " 597,\n",
       " 598,\n",
       " 602,\n",
       " 604,\n",
       " 622,\n",
       " 625,\n",
       " 629,\n",
       " 632,\n",
       " 666,\n",
       " 669,\n",
       " 671,\n",
       " 672,\n",
       " 674,\n",
       " 682,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 713,\n",
       " 714,\n",
       " 718,\n",
       " 719,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 737,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 755,\n",
       " 758,\n",
       " 760,\n",
       " 761,\n",
       " 764,\n",
       " 765,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 784,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 803,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 815,\n",
       " 820,\n",
       " 821,\n",
       " 827,\n",
       " 830,\n",
       " 833,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 849,\n",
       " 850,\n",
       " 853,\n",
       " 862,\n",
       " 867,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 890,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 909,\n",
       " 912,\n",
       " 915,\n",
       " 925,\n",
       " 926,\n",
       " 929,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 947,\n",
       " 953,\n",
       " 954,\n",
       " 959,\n",
       " 965,\n",
       " 968,\n",
       " 983,\n",
       " 984,\n",
       " 988,\n",
       " 989,\n",
       " 993,\n",
       " 995,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1002,\n",
       " 1015,\n",
       " 1017,\n",
       " 1018,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1028,\n",
       " 1032,\n",
       " 1037,\n",
       " 1039,\n",
       " 1044,\n",
       " 1046,\n",
       " 1047,\n",
       " 1051,\n",
       " 1062,\n",
       " 1064,\n",
       " 1065,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1079,\n",
       " 1085,\n",
       " 1100,\n",
       " 1101,\n",
       " 1109,\n",
       " 1117,\n",
       " 1118,\n",
       " 1120,\n",
       " 1121,\n",
       " 1131,\n",
       " 1135,\n",
       " 1136,\n",
       " 1147,\n",
       " 1148,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153,\n",
       " 1159,\n",
       " 1161,\n",
       " 1183,\n",
       " 1204,\n",
       " 1206,\n",
       " 1219,\n",
       " 1220,\n",
       " 1221,\n",
       " 1226,\n",
       " 1230,\n",
       " 1231,\n",
       " 1237,\n",
       " 1250,\n",
       " 1255,\n",
       " 1260,\n",
       " 1263,\n",
       " 1266,\n",
       " 1276,\n",
       " 1280,\n",
       " 1282,\n",
       " 1291,\n",
       " 1292,\n",
       " 1304,\n",
       " 1305,\n",
       " 1306,\n",
       " 1308,\n",
       " 1309,\n",
       " 1314,\n",
       " 1320,\n",
       " 1322,\n",
       " 1325,\n",
       " 1329,\n",
       " 1332,\n",
       " 1337,\n",
       " 1355,\n",
       " 1356,\n",
       " 1357,\n",
       " 1364,\n",
       " 1373,\n",
       " 1374,\n",
       " 1380,\n",
       " 1381,\n",
       " 1398,\n",
       " 1408,\n",
       " 1410,\n",
       " 1422,\n",
       " 1423,\n",
       " 1433,\n",
       " 1438,\n",
       " 1443,\n",
       " 1462,\n",
       " 1480,\n",
       " 1481,\n",
       " 1486,\n",
       " 1488,\n",
       " 1498,\n",
       " 1513,\n",
       " 1514,\n",
       " 1519,\n",
       " 1521,\n",
       " 1527,\n",
       " 1530,\n",
       " 1531,\n",
       " 1532,\n",
       " 1539,\n",
       " 1544,\n",
       " 1549,\n",
       " 1550,\n",
       " 1551,\n",
       " 1554,\n",
       " 1572,\n",
       " 1578,\n",
       " 1583,\n",
       " 1584,\n",
       " 1585,\n",
       " 1586,\n",
       " 1588,\n",
       " 1589,\n",
       " 1591,\n",
       " 1592,\n",
       " 1594,\n",
       " 1596,\n",
       " 1597,\n",
       " 1615,\n",
       " 1626,\n",
       " 1627,\n",
       " 1643,\n",
       " 1661,\n",
       " 1663,\n",
       " 1670,\n",
       " 1676,\n",
       " 1677,\n",
       " 1683,\n",
       " 1689,\n",
       " 1691,\n",
       " 1693,\n",
       " 1710,\n",
       " 1713,\n",
       " 1718,\n",
       " 1737,\n",
       " 1738,\n",
       " 1739,\n",
       " 1740,\n",
       " 1742,\n",
       " 1743,\n",
       " 1746,\n",
       " 1754,\n",
       " 1759,\n",
       " 1760,\n",
       " 1766,\n",
       " 1803,\n",
       " 1806,\n",
       " 1808,\n",
       " 1810,\n",
       " 1814,\n",
       " 1818}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/usr0/home/cyang3/Projects/py-analysis/tmp.txt') as f:\n",
    "    text = f.read().splitlines()\n",
    "ns = {int(l.split('/')[-2][3:-5]) for l in text}\n",
    "\n",
    "def extract_set(path):\n",
    "    with open(path) as f:\n",
    "        text = f.read().splitlines()\n",
    "    return {int(l.split('/')[-2][3:-5]) for l in text}\n",
    "\n",
    "finals = extract_set(\"../finals.txt\")\n",
    "multileak = extract_set(\"../multileak.txt\")\n",
    "notrain = extract_set(\"../tmp.txt\")\n",
    "notest = extract_set('../notest.txt')\n",
    "novaltest = extract_set('../novaltest.txt')\n",
    "(finals - notrain) - multileak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add_dummy_feature|binarize|label_binarize|maxabs_scale|minmax_scale|normalize|quantile_transform|robust_scale|scale|power_transform'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''preprocessing.add_dummy_feature(X[, value])\n",
    "\n",
    "Augment dataset with an additional dummy feature.\n",
    "\n",
    "preprocessing.binarize(X, *[, threshold, copy])\n",
    "\n",
    "Boolean thresholding of array-like or scipy.sparse matrix.\n",
    "\n",
    "preprocessing.label_binarize(y, *, classes)\n",
    "\n",
    "Binarize labels in a one-vs-all fashion.\n",
    "\n",
    "preprocessing.maxabs_scale(X, *[, axis, copy])\n",
    "\n",
    "Scale each feature to the [-1, 1] range without breaking the sparsity.\n",
    "\n",
    "preprocessing.minmax_scale(X[, ...])\n",
    "\n",
    "Transform features by scaling each feature to a given range.\n",
    "\n",
    "preprocessing.normalize(X[, norm, axis, ...])\n",
    "\n",
    "Scale input vectors individually to unit norm (vector length).\n",
    "\n",
    "preprocessing.quantile_transform(X, *[, ...])\n",
    "\n",
    "Transform features using quantiles information.\n",
    "\n",
    "preprocessing.robust_scale(X, *[, axis, ...])\n",
    "\n",
    "Standardize a dataset along any axis.\n",
    "\n",
    "preprocessing.scale(X, *[, axis, with_mean, ...])\n",
    "\n",
    "Standardize a dataset along any axis.\n",
    "\n",
    "preprocessing.power_transform(X[, method, ...])\n",
    "\n",
    "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like.\n",
    "'''\n",
    "fs = text.split('\\n')\n",
    "fs = [x.split('(')[0] for x in fs if '(' in x]\n",
    "fs = [x.replace('preprocessing.', '') for x in fs if ' ' not in x]\n",
    "# ori = 'accuracy_score|balanced_accuracy_score|top_k_accuracy_score|average_precision_score|brier_score_loss|f1_score|log_loss|precision_score|recall_score|jaccard_score|roc_auc_score|roc_auc_score|roc_auc_score|roc_auc_score|roc_auc_score|adjusted_mutual_info_score|adjusted_rand_score|completeness_score|fowlkes_mallows_score|homogeneity_score|mutual_info_score|normalized_mutual_info_score|rand_score|v_measure_score|explained_variance_score|max_error|mean_absolute_error|mean_squared_error|mean_squared_error|mean_squared_log_error|median_absolute_error|r2_score|mean_poisson_deviance|mean_gamma_deviance|mean_absolute_percentage_errors'\n",
    "# set(ori.split('|')) - set(fs)\n",
    "'|'.join(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"../tmp/log-03-28.txt\"\n",
    "input_path = \"../../GitHubAPI-Crawler/notebooks/2021-01-02/*\"\n",
    "os.system(f\"grep -l 'invo' {input_path}/Telemetry_Pre* | sort -V > {output_file}\")\n",
    "os.system(f\"grep -l '' {input_path}/FinalOver* | sort -V >> {output_file}\")\n",
    "os.system(f\"grep -l '' {input_path}/FinalNoTestDataWithMultiUse* | sort -V >> {output_file}\")\n",
    "# os.system(f\"grep -l 'invo' ../../GitHubAPI-Crawler/notebooks/2021-01-01/*/NoTest* | sort -V >> {output_file}\")\n",
    "# os.system(f\"grep -l 'invo' ../../GitHubAPI-Crawler/notebooks/2021-01-01/*/NoVal* | sort -V >> {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_query_code = '''\n",
    "var terf = document.getElementById('hyper-parameter-optimizers');\n",
    "var firstChilds = terf.querySelectorAll(\"td:first-child\");\n",
    "var allName = [];\n",
    "for(i=0; i<firstChilds.length; ++i){\n",
    "  allName.push(firstChilds[i].innerText.split('.')[1].split('(')[0]);\n",
    "}\n",
    "console.log(allName.join('|'));\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multitest samples:\n",
    "['../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_23-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_33-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_50-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_56-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_64-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_134-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_163-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_167-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_187-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_259-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_286-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_288-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_295-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_347-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_447-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_528-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_535-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_539-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_620-fact/MultiUseTestLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_656-fact/MultiUseTestLeak.csv']\n",
    "\n",
    "Overlap samples:\n",
    "<!-- ['../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_9-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_40-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_69-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_163-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_178-fact/Telemetry_OverlapLeak.csv', -->\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_212-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_264-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_279-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_413-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_416-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_427-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_469-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_507-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_511-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_535-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_539-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_618-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_620-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_679-fact/Telemetry_OverlapLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_703-fact/Telemetry_OverlapLeak.csv']\n",
    "\n",
    "Preprocessing samples:\n",
    "<!-- ['../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_10-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_55-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_64-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_135-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_149-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_169-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_216-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_268-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_273-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_275-fact/Telemetry_PreProcessingLeak.csv', -->\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_361-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_368-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_389-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_392-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_400-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_418-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_534-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_627-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_681-fact/Telemetry_PreProcessingLeak.csv',\n",
    " '../../GitHubAPI-Crawler/notebooks/2021-01-01/nb_694-fact/Telemetry_PreProcessingLeak.csv']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47e07d5b35dcb42740830b51565bb94080697db43eb73b7bb006bfe03e0d50dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
